# Counterexemplars

A **counterexemplar explanation** shows what should have been different to change the decision of an AI system. For example, a counterexemplars explanation could be a local explaination of a certain istance by providing the nearest istances that lead to a different decision or describing a small change in the input of the model that lead to a change in the outcome of the model.

You can find futher information about Counterexemplars term [here](../../Transparency/counterfactual.md)
