# Counterfactuals

A **counterfactual explanation** shows what should have been different to change the decision of an AI system. For example, a counterfactual explanation could be a local explaination of a certain istance by providing the nearest istances that lead to a different decision or describing a small change in the input of the model that lead to a change in the outcome of the model.

You can find futher information about Counterfactual term [here](../../Transparency/counterfactual.md)
