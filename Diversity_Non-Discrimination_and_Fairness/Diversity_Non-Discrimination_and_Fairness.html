
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Diversity, Non-Discrimination, and Fairness &#8212; The TAILOR Handbook of Trustworthy AI</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tailor.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://tailor.isti.cnr.it/handbookTAI/index.html/Diversity_Non-Discrimination_and_Fairness/Diversity_Non-Discrimination_and_Fairness.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Auditing AI" href="auditing.html" />
    <link rel="prev" title="Uncertainty" href="../Technical_Robustness_and_Safety/uncertainty.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/TAILOR-logo-coloured.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">The TAILOR Handbook of Trustworthy AI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Cerca in questo libro ..." aria-label="Cerca in questo libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../TAILOR.html">
   The TAILOR Handbook of Trustworthy AI
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../main/Ethical_Legal_Framework/Ethical_Legal_Framework.html">
   The Ethical and Legal Framework
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../main/Ethical_Legal_Framework/HLEG.html">
     Ethics Guidelines for Trustworthy AI by High-Level Expert Group on Artificial Intelligence
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../main/Ethical_Legal_Framework/AI_ACT.html">
     The EU AI Act
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../main/Ethical_Legal_Framework/Prohibited_AI.html">
       Prohibited AI Practices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../main/Ethical_Legal_Framework/High_Risk_AI.html">
       High Risk AI Systems
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../main/Trustworthy_AI.html">
   Trustworthy AI
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Human_Agency_and_Oversight/Human_Agency_and_Oversight.html">
     Human Agency and Oversight
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Human_Agency_and_Oversight/Meaningful_human_control.html">
       Meaningful human control
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Human_Agency_and_Oversight/Causal_responsibility.html">
       Causal Responsibility
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transparency/Transparency.html">
     Transparency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Transparency/XAI_dimensions.html">
       Dimensions of Explanations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/blackbox_transparent.html">
         Black Box Explanation vs Explanation by Design
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/model_specific.html">
         Model-Specific vs Model-Agnostic Explainers
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/global_local.html">
         Global vs Local Explanations
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Transparency/XAI.html">
       Explainable AI
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/XAI_kinds.html">
         Kinds of Explanations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/Technical_Robustness_and_Safety.html">
     Technical Robustness and Safety
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/alignment.html">
       Alignment
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/robustness.html">
       Robustness
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/reliability.html">
       Reliability
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/evaluation.html">
       Evaluation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/negative_side_effects.html">
       Negative side effects
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/distributional_shift.html">
       Distributional shift
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/security.html">
       Security
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/adversarial_attack.html">
       Adversarial Attack
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/data_poisoning.html">
       Data Poisoning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Technical_Robustness_and_Safety/uncertainty.html">
       Uncertainty
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="current reference internal" href="#">
     Diversity, Non-Discrimination, and Fairness
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auditing.html">
       Auditing AI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="bias.html">
       Bias
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="bias_factors.html">
       Bias Conducive Factors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="bias_lmm.html">
       Bias and Fairness in LLMs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="equity.html">
       Discrimination &amp; Equity
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="fairness.html">
       Fairness notions and metrics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="fair_ML.html">
       Fair Machine Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="discrimination.html">
       Grounds of Discrimination
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="intersectionality.html">
       Intersectionality
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="justice.html">
       Justice
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="segregation.html">
       Segregation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Accountability/Accountability_and_Reproducibility.html">
     Accountability
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Accountability/L2.Accountability.html">
       Accountability
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
      <label for="toctree-checkbox-11">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Accountability/L3.Wicked_problems.html">
         Wicked problems
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Accountability/L3.The_frame_problem.html">
         The Frame Problem
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Accountability/L3.Problem_of_many_hands.html">
         The Problem of Many Hands
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Accountability/L2.Reproducibility.html">
       Reproducibility
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Accountability/L2.Traceability.html">
       Traceability
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Accountability/L3.Provenance_tracking.html">
         Provenance Tracking
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Accountability/L3.Continuous_performance_monitoring.html">
         Continuous Performance Monitoring
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Privacy_and_Data_Governance/Privacy_and_Data_Governance.html">
     Privacy and Data Governance
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L1.anonymization.html">
       Data Anonymization (and Pseudonymization)
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.pseudonymization.html">
         Pseudonymization
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L1.privacy_model.html">
       Privacy Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.randomization.html">
         Randomization Methods
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.differential_privacy.html">
         Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.indistinguishability.html">
         Anonymity by Indistinguishability
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.federated.html">
         Federated Learning
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L1.attacks.html">
       Attacks on anonymization schemes
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.reidentification.html">
         Re-identification Attack
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/Societal_and_Environmental_Wellbeing.html">
     Societal and Environmental Wellbeing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/sustenaible_AI.html">
       Sustainable AI
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/greenAI.html">
         Green AI
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/cloud_computing.html">
         Cloud Computing
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/edge_computing.html">
         Edge Computing
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/data_centre.html">
         Data Centre
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/cradle_to_cradle.html">
         Cradle-to-cradle Design
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/resource_prediction.html">
         Resource Prediction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/resource_allocation.html">
         Resource Allocation
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/social_impact.html">
       Social Impact of AI Systems
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
      <label for="toctree-checkbox-19">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/human_interaction.html">
         AI human interaction
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/workforce_impact.html">
         AI Impact on the Workforce
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/society_and_democracy.html">
       Society and Democracy
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
      <label for="toctree-checkbox-20">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/social_scoring.html">
         AI for social scoring
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/propaganda.html">
         AI for propaganda
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TAILOR_project.html">
   The TAILOR project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../authors.html">
   Complete List of Contributors
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../main/AnalyticalIndex.html">
   Index
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/2CC2.html">
     2CC2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Accountability.html">
     Accountability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/propaganda.html">
     AI for propaganda
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/social_scoring.html">
     AI for social scoring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/human_interaction.html">
     AI human interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/workforce_impact.html">
     AI Impact on the Workforce
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Alignment.html">
     Alignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20attack.html">
     Adversarial Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20example.html">
     Adversarial Example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20input.html">
     Adversarial Input
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Indistinguishability.html">
     Anonymity by Indistinguishability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Ante-hoc%20Explanation.html">
     Ante-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Assessment.html">
     Assessment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Attacks%20Anonym.html">
     Attacks on Anonymization Schema
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Attacks%20on%20Pseudonymised%20Data.html">
     Attacks on Pseudonymised Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Auditing.html">
     Auditing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Bias.html">
     Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/bias_factors.html">
     Bias Conducive Factors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/bias_lmm.html">
     Bias and Fairness in LLMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Black-box%20Explanations.html">
     Black-box Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Brittleness.html">
     Brittleness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/C2C.html">
     C2C
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Human_Agency_and_Oversight/Causal_responsibility.html">
     Causal Responsibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Cloud%20Computing.html">
     Cloud Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Continuous%20monitoring.html">
     Continuous Performance Monitoring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Counterexemplar.html">
     Counterexemplars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Counterfactual.html">
     Counterfactuals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/cradle%202%20cradle.html">
     Cradle 2 cradle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Cradle.html">
     Cradle-to-cradle Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Data%20Anonymization.html">
     Data Anonymization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Data%20Center.html">
     Data Center
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Data%20Poisoning.html">
     Data Poisoning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Dependability.html">
     Dependability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Differential%20Privacy%20models.html">
     Differential Privacy Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/emotional_impact.html">
     Emotional Impact
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/epsilon_delta-differential_privacy.html">
     (
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     ,
     <span class="math notranslate nohighlight">
      \(\delta\)
     </span>
     )-Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Epsilon-differential_privacy.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Epsilon-indist.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Indistinguishability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Data%20Shift.html">
     Distributional Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Dimensions%20of%20Explanations.html">
     Dimensions of Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Discrimination.html">
     Grounds of Discrimination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Distributional%20Shift.html">
     Distributional Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Direct.html">
     Direct Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Edge%20Computing.html">
     Edge Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Energy%20Aware.html">
     Energy-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Energy%20Efficient.html">
     Energy-efficient Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Evaluation.html">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Equity.html">
     Equity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Exemplars.html">
     Exemplars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Explainable%20AI.html">
     Explainable AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Explanation%20by%20Design.html">
     Explanation by Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Fair%20Machine%20Learning.html">
     Fair Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Fairness.html">
     Fairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Features%20Importance.html">
     Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Federated.html">
     Federated Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Frame.html">
     The Frame Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Fog%20Computing.html">
     Fog Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Generalizable%20XAI.html">
     Model Agnostic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Global%20Explanations.html">
     Global Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20AI.html">
     Green AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20Computing.html">
     Green Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20IT.html">
     Green IT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/ICT%20sustainability.html">
     ICT sustainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Intended.html">
     Intended Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/intersectionality.html">
     Intersectionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Justice.html">
     Justice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/K-Anonymity.html">
     K-anonymity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/L_diversity.html">
     l-diversity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Linking%20Attack.html">
     Linking Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Local%20Explanations.html">
     Local Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Lore.html">
     Local Rule-based Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Human_Agency_and_Oversight/Meaningful_human_control.html">
     Meaningful Human Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Measurement.html">
     Measurement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Mesh%20Computing.html">
     Mesh Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Misdirect.html">
     Misdirect Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Model-Agnostic.html">
     Model Agnostic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Model-Specific.html">
     Model Specific
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Negative%20Side%20Effects.html">
     Negative Side Effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Not%20Generalizable%20XAI.html">
     Model Specific
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Perturbation.html">
     Achiving Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Post-hoc%20Explanations.html">
     Post-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Power%20Aware.html">
     Power-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Privacy%20model.html">
     Privacy models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Problem_of_many_hands.html">
     Problem of Many Hands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Prototypes.html">
     Prototypes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Provenance.html">
     Provenance Tracking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Pseudonymised%20Data.html">
     Pseudonymization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Randomization.html">
     Randomization Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Re-identification%20Attack.html">
     Re-identification Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Regenerative%20Design.html">
     Regenerative Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Reliability.html">
     Reliability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Repeatability.html">
     Repeatability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Replicability.html">
     Replicability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Reproducibility.html">
     Reproducibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Allocation.html">
     Resource Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Prediction.html">
     Resource Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Scheduling.html">
     Resource Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Robustness.html">
     Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Rules.html">
     Rules List and Rules Set
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Saliency%20Maps.html">
     Saliency Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Security.html">
     Security
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Segregation.html">
     Segregation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/self-identification.html">
     Self-identification of AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Single%20Tree%20Approximation.html">
     Single Tree Approxiamation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/social_impact.html">
     Social Impact of AI Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/society_and_democracy.html">
     Society and Democracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/T_closeness.html">
     t-closeness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Testing.html">
     Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Traceability.html">
     Traceability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Transparency.html">
     Transparency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Unintended.html">
     Unintended Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/XAI.html">
     XAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Wicked.html">
     Wicked Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Workload%20Forecast.html">
     Workload Forecast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Workload%20Prediction.html">
     Workload Prediction
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Attiva / disattiva la navigazione" aria-controls="site-navigation"
                title="Attiva / disattiva la navigazione" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Scarica questa pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Diversity_Non-Discrimination_and_Fairness/Diversity_Non-Discrimination_and_Fairness.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Scarica il file sorgente" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Stampa in PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/prafra/jupyter-book-TAILOR-D3.2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repository di origine"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/prafra/jupyter-book-TAILOR-D3.2/issues/new?title=Issue%20on%20page%20%2FDiversity_Non-Discrimination_and_Fairness/Diversity_Non-Discrimination_and_Fairness.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Apri un problema"><i class="fas fa-lightbulb"></i>questione aperta</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modalità schermo intero"
        title="Modalità schermo intero"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenuti
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-brief">
   In brief
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivations-and-background">
   Motivations and background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standards-and-guidelines">
   Standards and guidelines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#software-frameworks-supporting-dimension">
   Software frameworks supporting dimension
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main-keywords">
   Main keywords
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliography">
   Bibliography
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="diversity-non-discrimination-and-fairness">
<h1>Diversity, Non-Discrimination, and Fairness<a class="headerlink" href="#diversity-non-discrimination-and-fairness" title="Permalink to this headline">¶</a></h1>
<div class="section" id="in-brief">
<h2>In brief<a class="headerlink" href="#in-brief" title="Permalink to this headline">¶</a></h2>
<p>The term fairness is defined as the quality or state of being fair; or a
lack of favoritism towards one side. However, fairness can mean
different concepts to different peoples, different contexts, and
different disciplines <span id="id1">[<a class="reference internal" href="fairness.html#id2563">1</a>]</span>. An unfair Artificial
Intelligence (AI) model produces results that are biased towards
particular individuals or groups. The most relevant case of bias is
discrimination against protected-by-law social groups. Equity requires
that people are treated according to their needs, which does not mean
all people are treated equally <span id="id2">[<a class="reference internal" href="#id2429">2</a>]</span>. Justice is the
“fair and equitable treatment of all individuals under the law”
<span id="id3">[<a class="reference internal" href="justice.html#id2483">1</a>]</span>.</p>
</div>
<div class="section" id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this headline">¶</a></h2>
<p>We first provide motivations and background on fairness, equity and justice in AI.  This consists of warnings and legal obligations about potential harms of unscrutinized AI tools, especially in socially sensitive decision making. A taxonomy of fair-AI algorithms is then presented, based on the step of the AI development process in which fairness is checked/controlled for. Next, we summarize the guidelines and draft standards for fair-AI, and the software frameworks supporting the dimension. Finally, the main keywords of the dimension are extensively detailed.</p>
</div>
<div class="section" id="motivations-and-background">
<h2>Motivations and background <a class="footnote-reference brackets" href="#readapt" id="id4">1</a><a class="headerlink" href="#motivations-and-background" title="Permalink to this headline">¶</a></h2>
<p>Increasingly sophisticated algorithms from AI and Machine Learning (ML) support knowledge discovery from big data of human activity.
They enable the extraction of patterns and profiles of human behavior which are able to make extremely accurate predictions.
Decisions are then being partly or fully delegated to such algorithms for a wide range of socially sensitive tasks: personnel selection and wages, credit scoring, criminal justice, assisted diagnosis in medicine, personalization in schooling, sentiment analysis in texts and images, people monitoring through facial recognition, news recommendation, community bulding in social networks, dynamic pricing of services and products.</p>
<p>The benefits of algorithmic-based decision making cannot be neglected, e.g., procedural regularity – same procedure applied to each data subject. However, automated decisions based on profiling or social sorting may be biased <span id="id5">[<a class="reference internal" href="bias.html#id2432">1</a>, <a class="reference internal" href="bias.html#id2668">2</a>]</span> for several reasons. Historical data may contain human (cognitive) bias and discriminatory practices that are endemic, to which the algorithms assign the status of general rules. Also, the usage of AI/ML models reinforces such practices because data about model’s decisions become inputs in subsequent model construction (feedback loops).
Algorithms may wrongly interpret spurious correlations in data as causation, making predictions based on ungrounded reasons. Moreover, algorithms pursue the utilitarian optimization of quality metrics, such as accuracy of predictions, that favor precision over the majority of people against small groups. Finally, the technical process of designing and deploying algorithms is not yet mature and standardized. Rather, it is full of small and big decisions (sometimes, trial and error steps) that may hide bias, such as selecting non-representative data, performing overspecialization of the models, ignoring socio-technical impacts, or using models in deployment contexts they are not tested for. These risks are exacerbated by the fact that the AI/ML models are extremely large and complex for human understanding, or not even intelligible, sometimes they are based on randomness or time-dependent non-reproducible conditions <span id="id6">[<a class="reference internal" href="#id2463">6</a>]</span>.</p>
<p>Legal restrictions on automated decision-making are provided by the EU
General Data Protection Regulation, which states (<a href="https://gdpr-info.eu/art-22-gdpr/" target=_blank>Article 22</a>) “the right
not to be subject to a decision based solely on automated processing”.
Moreover, (<a href="https://gdpr-info.eu/recitals/no-71/" target=_blank>Recital 71</a>) “in order to ensure fair and transparent
processing in respect of the data subject […] the controller should
use appropriate mathematical or statistical procedures […] to
prevent, inter alia, discriminatory effects on natural persons”.</p>
<p>Fair algorithms are designed with the purpose of preventing biased decisions in algorithmic decision making.  Quantitative definitions have been
introduced in philosophy, economics, and machine learning in the last 50 years
<span id="id7">[<a class="reference internal" href="#id2428">7</a>, <a class="reference internal" href="#id2427">8</a>, <a class="reference internal" href="auditing.html#id2452">1</a>]</span>,
with more than 20 different definitions of fairness appeared thus far in
the computer science literature
<span id="id8">[<a class="reference internal" href="bias.html#id2424">3</a>, <a class="reference internal" href="#id2493">11</a>]</span>.
Four non-mutually exclusive strategies can be devised for
fairness-by-design of AI/ML models.</p>
<p><em>Pre-processing approaches.</em> They consists of a controlled sanitization of the data used to train an AI/ML model with respect to specific biases. Pre-processing approaches allow for obtaining less biased data, which can be used for training AI/ML models. An advantage of pre-processing approaches is that they are independent of the AI/ML model and algorithm at hand.</p>
<p><em>In-processing approaches.</em> The second strategy is to modify the AI/ML algorithm, by incorporating fairness criteria in model construction, such as regularizing the optimization objective with a fairness measure. There is a fast growing adoption of in-processing approaches in many AI/ML problems other than in the original setting of classification, including ranking, clustering, community detection, influence maximization, distribution/allocation of goods, and models on non-structured data such as natural language texts and images.
An area somehow in the middle between pre-processing and in-processing approaches is fair representation learning, where the model inferred from data is not used directly for decision making, but rather as intermediate knowledge.</p>
<p><em>Post-processing approaches.</em> This strategy consists of post-processing an AI/ML model once it has been computed, so to identify and remove unfair decision paths. This can be achieved also by involving human experts in the exploration and interpretation of the model or of the model’s decisions.
Post-processing approaches consist of altering the model’s internals, for instance by correcting the confidence of classification rules, or the probabilities of Bayesian models. Post-processing becomes necessary for tasks for which there is no in-processing approach explicitly designed for the fairness requirement at hand.</p>
<p><em>Prediction-time approaches.</em> The last strategy assumes no change in the construction of AI/ML models, but rather correcting their predictions at run-time. Proposed approaches include promoting, demoting or rejecting predictions close to the decision boundary,  differentiating the decision boundary itself over different social groups, or wrapping a fair classifier on top of a black-box base classifier. Such approaches may be applied to legacy software, including non-AI/ML algorithms, that cannot be replaced by in-processing approaches or changed by post-processing approaches.</p>
</div>
<div class="section" id="standards-and-guidelines">
<h2>Standards and guidelines<a class="headerlink" href="#standards-and-guidelines" title="Permalink to this headline">¶</a></h2>
<p>Several initiatives have started to audit, standardize and certify algorithmic fairness, such as the <a class="reference external" href="https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-on-the-draft-ai-auditing-framework-guidance-for-organisations">ICO Draft on AI Auditing
Framework</a>,
the draft <a class="reference external" href="https://standards.ieee.org/project/7003.html">IEEE P7003™ Standard on Algorithmic Bias
Considerations</a>, the <a class="reference external" href="https://standards.ieee.org/industry-connections/ecpais.html">IEEE
Ethics Certification Program for Autonomous and Intelligent
Systems</a>,
and the <a class="reference external" href="https://www.iso.org/standard/77607.html">ISO/IEC TR 24027:2021 Bias in AI systems and AI aided decision
making</a> (see also the entry on
<a class="reference internal" href="auditing.html"><span class="doc">Auditing AI</span></a>). Regarding the issue of equality data collection, the European Union
High Level Group on Non-discrimination, Equality and Diversity has set
up “<a class="reference external" href="https://ec.europa.eu/info/sites/default/files/en-guidelines-improving-collection-and-use-of-equality-data.pdf">Guidelines on improving the collection and use of equality
data</a>”,
and the European Union Agency for Fundamental Rights (FRA) maintains <a href="https://fra.europa.eu/en/promising-practices-list" target=_blank>a
list</a> of promising practices for equality data collection.</p>
<p>Very few scientific works attempt at investigating the practical applicability of fairness in AI
<span id="id9">[<a class="reference internal" href="#id2436">12</a>, <a class="reference internal" href="#id2435">13</a>]</span>.
This issue is challenging, and likely to require domain-specific
approaches <span id="id10">[<a class="reference internal" href="#id2434">14</a>]</span>. On the educational side,
however, there are hundreds of university courses on technology ethics
<span id="id11">[<a class="reference internal" href="#id2437">15</a>]</span>, many of which cover fairness in AI.</p>
</div>
<div class="section" id="software-frameworks-supporting-dimension">
<h2>Software frameworks supporting dimension<a class="headerlink" href="#software-frameworks-supporting-dimension" title="Permalink to this headline">¶</a></h2>
<!--The landscape of software libraries and tools is very large. Existing
proposals cover almost every step of the data-friven AI development
process (data collection, data processing, model development, model
deployment, model monitoring), every type of AI models (classification,
regression, clustering, ranking, community detection, influence
maximization, distribution/allocation of goods), and every type of data
(tabular, text, images, videos). Reviews and critical discussions of
gaps for a few fairness toolkits can be found in
{cite}`lee2021landscape,DBLP:journals/corr/abs-2112-05700`.-->
<p>The landscape of software libraries and tools is very large. Existing proposals cover almost every step of the data-friven AI development process (data collection, data processing, model development, model deployment, model monitoring), every type of AI models (classification, regression, clustering, ranking, community detection, influence maximization, distribution/allocation of goods), and every type of data (tabular, text, images, videos).</p>
<p>Reviews and critical discussions of gaps for a few fairness toolkits can be found in~<span id="id12">[<a class="reference internal" href="fair_ML.html#id2578">1</a>, <a class="reference internal" href="#id2438">17</a>]</span>.</p>
</div>
<div class="section" id="main-keywords">
<h2>Main keywords<a class="headerlink" href="#main-keywords" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="auditing.html"><span class="doc">Auditing AI</span></a>: <strong>Auditing AI</strong> aims to identify and address possible risks and impacts while ensuring robust and trustworthy (see <a class="reference internal" href="../Accountability/L2.Accountability.html"><span class="doc">Accountability</span></a>).</p></li>
<li><p><a class="reference internal" href="bias.html"><span class="doc">Bias</span></a>: <strong>Bias</strong> refers to an inclination towards or against a particular individual, group, or sub-groups. AI models may inherit biases from training data or introduce new forms of bias.</p></li>
<li><p><a class="reference internal" href="bias_factors.html"><span class="doc">Bias Conducive Factors</span></a>: <strong>Bias conducive factors</strong> are aspects of individuals and institutions that lead to biases in data-driven models by influencing data and tech development. This entry presents a selection of bias conducive factors in algorithmic hiring.</p></li>
<li><p><a class="reference internal" href="bias_lmm.html"><span class="doc">Bias and Fairness in LLMs</span></a>: within the Natural Language Processing (NLP) field, bias manifests in several forms, possibly leading to harms and unfairness. We review here intrinsic, lantent bias; extrinsic harms, and data selection bias in Large Language Models (LLMs).</p></li>
<li><p><a class="reference internal" href="equity.html"><span class="doc">Discrimination &amp; Equity</span></a>: Forms of bias that count as discrimination against social groups or individuals should be avoided, both from legal and ethical perspectives. Discrimination can be direct or indirect, intentional or unintentional.</p></li>
<li><p><a class="reference internal" href="fairness.html"><span class="doc">Fairness notions and metrics</span></a>: The term <strong>fairness</strong> is defined as the quality or state of being fair; or a lack of favoritism towards one side. The notions of fairness, and quantitative measures of them (fairness metrics), can be distinguished based on the focus on individuals, groups and sub-groups.</p></li>
<li><p><a class="reference internal" href="fair_ML.html"><span class="doc">Fair Machine Learning</span></a>: <strong>Fair Machine Learning</strong> models take into account the issues of bias and fairness. Approaches can be categorized as pre-processig, which transform the input data, as in-processing, which modify the learning algorithm, and post-processing, which alter models’ internals or their decisions.</p></li>
<li><p><a class="reference internal" href="discrimination.html"><span class="doc">Grounds of Discrimination</span></a>: international and national laws prohibit <strong>discriminating on some explicitly defined grounds</strong>, such as race, sex, religion, etc. They can be considered in isolation, or interacting, giving rise to multiple discrimination and intersectional discrimination.
-<a class="reference internal" href="intersectionality.html"><span class="doc">Intersectionality</span></a>: <strong>Intersectionality</strong> focuses on a specific type of bias due to the combination of sensitive factors. An individual might not be discriminated against based on race or based on gender only, but she might be discriminated against because of a combination of both. Black women are particularly prone to this type of discrimination.</p></li>
<li><p><a class="reference internal" href="justice.html"><span class="doc">Justice</span></a>: <strong>Justice</strong> encompasses three different perspectives: (1) <em>fairness</em> understood as the fair treatment of people, (2) <em>rightness</em> as the quality of being fair or reasonable, and (3) a legal system, the scheme or system of law. Justice can be distinguished between <em>substantive</em> and <em>procedural</em>.</p></li>
<li><p><a class="reference internal" href="segregation.html"><span class="doc">Segregation</span></a>: <strong>Social segregation</strong> refers to the separation of groups on the grounds of personal or cultural traits. Separation can be physical (e.g., in schools or neighborhoods) or virtual (e.g., in social networks).</p></li>
</ul>
</div>
<div class="section" id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<p id="id13"><dl class="citation">
<dt class="label" id="id2536"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Deirdre K Mulligan, Joshua A Kroll, Nitin Kohli, and Richmond Y Wong. This thing called fairness: disciplinary confusion realizing a value in technology. <em>Proceedings of the ACM on Human-Computer Interaction</em>, 3(CSCW):1–36, 2019.</p>
</dd>
<dt class="label" id="id2429"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Martha Minow. Equality vs. Equity. <em>American Journal of Law and Equality</em>, 1:167–193, 2021.</p>
</dd>
<dt class="label" id="id2456"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Jeffrey Lehman, Shirelle Phelps, and others. <em>West's encyclopedia of American law</em>. Thomson/Gale, 2004.</p>
</dd>
<dt class="label" id="id2433"><span class="brackets"><a class="fn-backref" href="#id5">4</a></span></dt>
<dd><p>Eirini Ntoutsi, Pavlos Fafalios, Ujwal Gadiraju, Vasileios Iosifidis, Wolfgang Nejdl, Maria-Esther Vidal, Salvatore Ruggieri, Franco Turini, Symeon Papadopoulos, Emmanouil Krasanakis, Ioannis Kompatsiaris, Katharina Kinder-Kurlanda, Claudia Wagner, Fariba Karimi, Miriam Fernández, Harith Alani, Bettina Berendt, Tina Kruegel, Christian Heinze, Klaus Broelemann, Gjergji Kasneci, Thanassis Tiropanis, and Steffen Staab. Bias in data-driven artificial intelligence systems - an introductory survey. <em>WIREs Data Mining Knowl. Discov.</em>, 2020.</p>
</dd>
<dt class="label" id="id2669"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Jose M. Alvarez, Alejandra Bringas Colmenarejo, Alaa Elobaid, Simone Fabbrizzi, Miriam Fahimi, Antonio Ferrara, Siamak Ghodsi, Carlos Mougan, Ioanna Papageorgiou, Paula Reyero, Mayra Russo, Kristen M. Scott, Laura State, Xuan Zhao, and Salvatore Ruggieri. Policy advice and best practices on bias and fairness in AI. <em>Ethics Inf. Technol.</em>, 26(2):31, 2024.</p>
</dd>
<dt class="label" id="id2463"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Joshua A. Kroll, Joanna Huey, Solon Barocas, Edward W. Felten, Joel R. Reidenberg, David G. Robinson, and Harlan Yu. Accountable algorithms. <em>U. of Penn. Law Review</em>, 165:633–705, 2017.</p>
</dd>
<dt class="label" id="id2428"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p>Ben Hutchinson and Margaret Mitchell. 50 years of test (un)fairness: lessons for machine learning. In <em>FAT</em>, 49–58. ACM, 2019.</p>
</dd>
<dt class="label" id="id2427"><span class="brackets"><a class="fn-backref" href="#id7">8</a></span></dt>
<dd><p>Reuben Binns. Fairness in machine learning: lessons from political philosophy. In <em>FAT</em>, volume 81 of Proceedings of Machine Learning Research, 149–159. PMLR, 2018.</p>
</dd>
<dt class="label" id="id2439"><span class="brackets"><a class="fn-backref" href="#id7">9</a></span></dt>
<dd><p>Andrea Romei and Salvatore Ruggieri. A multidisciplinary survey on discrimination analysis. <em>Knowl. Eng. Rev.</em>, 29(5):582–638, 2014.</p>
</dd>
<dt class="label" id="id2425"><span class="brackets"><a class="fn-backref" href="#id8">10</a></span></dt>
<dd><p>Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey on bias and fairness in machine learning. <em>ACM Comput. Surv.</em>, 54(6):115:1–115:35, 2021.</p>
</dd>
<dt class="label" id="id2493"><span class="brackets"><a class="fn-backref" href="#id8">11</a></span></dt>
<dd><p>Indre Zliobaite. Measuring discrimination in algorithmic decision making. <em>Data Min. Knowl. Discov.</em>, 31(4):1060–1089, 2017.</p>
</dd>
<dt class="label" id="id2436"><span class="brackets"><a class="fn-backref" href="#id9">12</a></span></dt>
<dd><p>Karima Makhlouf, Sami Zhioua, and Catuscia Palamidessi. On the applicability of machine learning fairness notions. <em>SIGKDD Explor.</em>, 23(1):14–23, 2021.</p>
</dd>
<dt class="label" id="id2435"><span class="brackets"><a class="fn-backref" href="#id9">13</a></span></dt>
<dd><p>Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof, and Ed H. Chi. Putting fairness principles into practice: challenges, metrics, and improvements. In <em>AIES</em>, 453–459. ACM, 2019.</p>
</dd>
<dt class="label" id="id2434"><span class="brackets"><a class="fn-backref" href="#id10">14</a></span></dt>
<dd><p>Michelle Seng Ah Lee and Luciano Floridi. Algorithmic fairness in mortgage lending: from absolute conditions to relational trade-offs. <em>Minds Mach.</em>, 31(1):165–191, 2021.</p>
</dd>
<dt class="label" id="id2437"><span class="brackets"><a class="fn-backref" href="#id11">15</a></span></dt>
<dd><p>Casey Fiesler, Natalie Garrett, and Nathan Beard. What do we teach when we teach tech ethics?: A syllabi analysis. In <em>SIGCSE</em>, 289–295. ACM, 2020.</p>
</dd>
<dt class="label" id="id2575"><span class="brackets"><a class="fn-backref" href="#id12">16</a></span></dt>
<dd><p>Michelle Seng Ah Lee and Jatinder Singh. The landscape and gaps in open source fairness toolkits. In <em>CHI</em>, 699:1–699:13. ACM, 2021.</p>
</dd>
<dt class="label" id="id2438"><span class="brackets"><a class="fn-backref" href="#id12">17</a></span></dt>
<dd><p>Brianna Richardson and Juan E. Gilbert. A framework for fairness: A systematic review of existing fair AI solutions. <em>CoRR</em>, 2021.</p>
</dd>
<dt class="label" id="id2462"><span class="brackets"><a class="fn-backref" href="#id2923">18</a></span></dt>
<dd><p>Salvatore Ruggieri. Algorithmic fairness. In <em>Elgar Encyclopedia of Law and Data Science</em>. Edward Elgar Publishing Limited, 2022.</p>
</dd>
</dl>
</p>
<blockquote>
<div><p>This entry was written by Salvatore Ruggieri.</p>
</div></blockquote>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="readapt"><span class="brackets"><a class="fn-backref" href="#id4">1</a></span></dt>
<dd><p>This Section was readapted from <span id="id2923">[<a class="reference internal" href="#id2462">18</a>]</span>.</p>
</dd>
</dl>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Diversity_Non-Discrimination_and_Fairness"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../Technical_Robustness_and_Safety/uncertainty.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Uncertainty</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="auditing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Auditing AI</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          Di varii auctores; see <a href="/handbookTAI/authors.html" target="_blank">here</a> for the complete list of contributors. This research was partially supported by TAILOR, a project funded by EU Horizon 2020 research and innovation programme under GA No 952215<br/>
        
            &copy; Diritto d'autore 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>