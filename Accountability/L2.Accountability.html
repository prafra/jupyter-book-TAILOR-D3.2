
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Accountability &#8212; The TAILOR Handbook of Trustworthy AI</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tailor.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://tailor.isti.cnr.it/handbookTAI/index.html/Accountability/L2.Accountability.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Wicked problems" href="L3.Wicked_problems.html" />
    <link rel="prev" title="Accountability and Reproducibility" href="Accountability_and_Reproducibility.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/TAILOR-logo-coloured.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">The TAILOR Handbook of Trustworthy AI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Cerca in questo libro ..." aria-label="Cerca in questo libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../TAILOR.html">
   The TAILOR Handbook of Trustworthy AI
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../authors.html">
   Complete List of Contributors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../main/Trustworthy_AI.html">
   Trustworthy AI
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../main/Ethical_Legal_Framework/Ethical_Legal_Framework.html">
   The Ethical and Legal Framework
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../main/Ethical_Legal_Framework/HLEG.html">
     Ethics Guidelines for Trustworthy AI by High-Level Expert Group on Artificial Intelligence
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../main/Ethical_Legal_Framework/AI_ACT.html">
     The EU AI Act
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../main/Ethical_Legal_Framework/Prohibited_AI.html">
       Prohibited AI Practices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../main/Ethical_Legal_Framework/High_Risk_AI.html">
       High Risk AI Systems
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Human_Agency_and_Oversight/Human_Agency_and_Oversight.html">
   Human Agency and Oversight
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Human_Agency_and_Oversight/Meaningful_human_control.html">
     Meaningful human control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Human_Agency_and_Oversight/Causal_responsibility.html">
     Causal Responsibility
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Transparency/Transparency.html">
   Transparency
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transparency/XAI_dimensions.html">
     Dimensions of Explanations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transparency/blackbox_transparent.html">
       Black Box Explanation vs Explanation by Design
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transparency/model_specific.html">
       Model-Specific vs Model-Agnostic Explainers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Transparency/global_local.html">
       Global vs Local Explanations
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Transparency/XAI.html">
     Explainable AI
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Transparency/XAI_kinds.html">
       Kinds of Explanations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/counterfactual.html">
         Counterfactuals
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/feature_importance.html">
         Feature Importance
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/saliency_maps.html">
         Saliency Maps
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Transparency/single_tree.html">
         Single Tree Approximation
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Technical_Robustness_and_Safety/Technical_Robustness_and_Safety.html">
   Technical Robustness and Safety
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/alignment.html">
     Alignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/robustness.html">
     Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/reliability.html">
     Reliability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/evaluation.html">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/negative_side_effects.html">
     Negative side effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/distributional_shift.html">
     Distributional shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/security.html">
     Security
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/adversarial_attack.html">
     Adversarial Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Technical_Robustness_and_Safety/data_poisoning.html">
     Data Poisoning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/Diversity_Non-Discrimination_and_Fairness.html">
   Diversity, Non-Discrimination, and Fairness
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/auditing.html">
     Auditing AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/bias.html">
     Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/bias_factors.html">
     Bias Conducive Factors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/bias_lmm.html">
     Bias and Fairness in LLMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/equity.html">
     Discrimination &amp; Equity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/fairness.html">
     Fairness notions and metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/fair_ML.html">
     Fair Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/discrimination.html">
     Grounds of Discrimination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/intersectionality.html">
     Intersectionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/justice.html">
     Justice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/segregation.html">
     Segregation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Accountability_and_Reproducibility.html">
   Accountability
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="current reference internal" href="#">
     Accountability
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="L3.Wicked_problems.html">
       Wicked problems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="L3.The_frame_problem.html">
       The Frame Problem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="L3.Problem_of_many_hands.html">
       The Problem of Many Hands
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="L2.Reproducibility.html">
     Reproducibility
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="L2.Traceability.html">
     Traceability
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="L3.Provenance_tracking.html">
       Provenance Tracking
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="L3.Continuous_performance_monitoring.html">
       Continuous Performance Monitoring
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Privacy_and_Data_Governance/Privacy_and_Data_Governance.html">
   Respect for Privacy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Privacy_and_Data_Governance/L1.anonymization.html">
     Data Anonymization (and Pseudonymization)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L2.pseudonymization.html">
       Pseudonymization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Privacy_and_Data_Governance/L1.privacy_model.html">
     Privacy Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L2.differential_privacy.html">
       Differential Privacy
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L3.epsilon_DP.html">
         <span class="math notranslate nohighlight">
          \(\epsilon\)
         </span>
         -Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L3.epsilon_delta_DP.html">
         (
         <span class="math notranslate nohighlight">
          \(\epsilon\)
         </span>
         ,
         <span class="math notranslate nohighlight">
          \(\delta\)
         </span>
         )-Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../Privacy_and_Data_Governance/L2.perturbation_mechanisms.html">
         Achieving Differential Privacy
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L2.k_anonymity.html">
       k-anonymity
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Privacy_and_Data_Governance/L1.attacks.html">
     Attacks on anonymization schemes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Privacy_and_Data_Governance/L2.reidentification.html">
       Re-identification Attack
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/Societal_and_Environmental_Wellbeing.html">
   Sustainability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/greenAI.html">
     Green AI
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/power_aware.html">
       Power-aware Computing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/cloud_computing.html">
     Cloud Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/edge_computing.html">
     Edge Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/data_centre.html">
     Data Centre
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/cradle_to_cradle.html">
     Cradle-to-cradle Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/resource_prediction.html">
     Resource Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Societal_and_Environmental_Wellbeing/resource_allocation.html">
     Resource Allocation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TAILOR_project.html">
   The TAILOR project
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../main/AnalyticalIndex.html">
   Index
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/2CC2.html">
     2CC2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Accountability.html">
     Accountability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Alignment.html">
     Alignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20attack.html">
     Adversarial Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20example.html">
     Adversarial Example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Adversarial%20input.html">
     Adversarial Input
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Ante-hoc%20Explanation.html">
     Ante-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Assessment.html">
     Assessment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Attacks%20Anonym.html">
     Attacks on Anonymization Schema
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Attacks%20on%20Pseudonymised%20Data.html">
     Attacks on Pseudonymised Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Auditing.html">
     Auditing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Bias.html">
     Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/bias_factors.html">
     Bias Conducive Factors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/bias_lmm.html">
     Bias and Fairness in LLMs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Black-box%20Explanations.html">
     Black-box Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Brittleness.html">
     Brittleness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/C2C.html">
     C2C
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Human_Agency_and_Oversight/Causal_responsibility.html">
     Causal Responsibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Cloud%20Computing.html">
     Cloud Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Continuous%20monitoring.html">
     Continuous Performance Monitoring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/cradle%202%20cradle.html">
     Cradle 2 cradle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Cradle.html">
     Cradle-to-cradle Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Data%20Anonymization.html">
     Data Anonymization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Data%20Center.html">
     Data Center
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Data%20Poisoning.html">
     Data Poisoning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Dependability.html">
     Dependability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Differential%20Privacy%20models.html">
     Differential Privacy Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/epsilon_delta-differential_privacy.html">
     (
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     ,
     <span class="math notranslate nohighlight">
      \(\delta\)
     </span>
     )-Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Epsilon-differential_privacy.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Epsilon-indist.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Indistinguishability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Data%20Shift.html">
     Distributional Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Dimensions%20of%20Explanations.html">
     Dimensions of Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Discrimination.html">
     Grounds of Discrimination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Distributional%20Shift.html">
     Distributional Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Direct.html">
     Direct Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Edge%20Computing.html">
     Edge Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Energy%20Aware.html">
     Energy-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Energy%20Efficient.html">
     Energy-efficient Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Evaluation.html">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Equity.html">
     Equity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Explanation%20by%20Design.html">
     Explanation by Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Fair%20Machine%20Learning.html">
     Fair Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Fairness.html">
     Fairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Features%20Importance.html">
     Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Frame.html">
     The Frame Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Fog%20Computing.html">
     Fog Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Generalizable%20XAI.html">
     Model Agnostic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Global%20Explanations.html">
     Global Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20AI.html">
     Green AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20Computing.html">
     Green Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Green%20IT.html">
     Green IT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/ICT%20sustainability.html">
     ICT sustainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Intended.html">
     Intended Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Justice.html">
     Justice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/K-Anonymity.html">
     K-anonymity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Linking%20Attack.html">
     Linking Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Local%20Explanations.html">
     Local Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Human_Agency_and_Oversight/Meaningful_human_control.html">
     Meaningful Human Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Measurement.html">
     Measurement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Mesh%20Computing.html">
     Mesh Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Misdirect.html">
     Misdirect Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Model-Agnostic.html">
     Model Agnostic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Model-Specific.html">
     Model Specific
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Negative%20Side%20Effects.html">
     Negative Side Effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Not%20Generalizable%20XAI.html">
     Model Specific
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Perturbation.html">
     Achiving Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Post-hoc%20Explanations.html">
     Post-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Power%20Aware.html">
     Power-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Privacy%20model.html">
     Privacy models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Problem_of_many_hands.html">
     Problem of Many Hands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Provenance.html">
     Provenance Tracking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Pseudonymised%20Data.html">
     Pseudonymization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy_and_Data_Governance/Re-identification%20Attack.html">
     Re-identification Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Regenerative%20Design.html">
     Regenerative Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Reliability.html">
     Reliability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Repeatability.html">
     Repeatability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Replicability.html">
     Replicability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Reproducibility.html">
     Reproducibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Allocation.html">
     Resource Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Prediction.html">
     Resource Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Resource%20Scheduling.html">
     Resource Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Robustness.html">
     Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Saliency%20Maps.html">
     Saliency Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Security.html">
     Security
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Diversity_Non-Discrimination_and_Fairness/Segregation.html">
     Segregation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Single%20Tree%20Approximation.html">
     Single Tree Approxiamation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Testing.html">
     Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Traceability.html">
     Traceability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency/Transparency.html">
     Transparency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Technical_Robustness_and_Safety/Unintended.html">
     Unintended Behaviour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability/Wicked.html">
     Wicked Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Workload%20Forecast.html">
     Workload Forecast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Societal_and_Environmental_Wellbeing/Workload%20Prediction.html">
     Workload Prediction
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Attiva / disattiva la navigazione" aria-controls="site-navigation"
                title="Attiva / disattiva la navigazione" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Scarica questa pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Accountability/L2.Accountability.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Scarica il file sorgente" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Stampa in PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/prafra/jupyter-book-TAILOR-D3.2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repository di origine"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/prafra/jupyter-book-TAILOR-D3.2/issues/new?title=Issue%20on%20page%20%2FAccountability/L2.Accountability.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Apri un problema"><i class="fas fa-lightbulb"></i>questione aperta</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modalità schermo intero"
        title="Modalità schermo intero"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenuti
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-brief">
   In Brief
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-background">
   Motivation and Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#guidelines">
   Guidelines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#possible-taxonomy-of-terms">
   Possible Taxonomy of terms
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#accountability-gaps-and-their-implications">
   Accountability gaps and their implications
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliography">
   Bibliography
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="accountability">
<h1>Accountability<a class="headerlink" href="#accountability" title="Permalink to this headline">¶</a></h1>
<div class="section" id="in-brief">
<h2>In Brief<a class="headerlink" href="#in-brief" title="Permalink to this headline">¶</a></h2>
<p><strong>Accountability</strong> is an ethical aspect studied in the <a href="https://tailor-network.eu/" target=_blank>TAILOR project</a> to ensure that a given actor or actors can render an account of the actions of an AI system. The accountability concept is strictly related to the concept of responsibility.</p>
</div>
<div class="section" id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this headline">¶</a></h2>
<p>According to <span id="id1">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span>, the requirement of accountability complements the other ethical dimensions, and is closely linked to the principle of <a class="reference internal" href="../Diversity_Non-Discrimination_and_Fairness/Diversity_Non-Discrimination_and_Fairness.html"><span class="doc std std-doc">fairness</span></a>. It necessitates that mechanisms be put in place to ensure responsibility and accountability for AI systems and their outcomes, both before and after their development, deployment and use.</p>
</div>
<div class="section" id="motivation-and-background">
<h2>Motivation and Background<a class="headerlink" href="#motivation-and-background" title="Permalink to this headline">¶</a></h2>
<p>Whenever something goes wrong, there is often a call to define who is responsible for this wrongdoing. Responsibility is a broader topic that might have different conceptualizations. However, in this sense, it usually means one’s obligation to render an account of your actions and the consequences of these, i.e. accountability. Accountability can be defined as a form of <em>“passive responsibility”</em> (or backward looking responsibility) in the sense of being held to account for or justify towards others a given action or consequence that happened in the past <span id="id2">[]</span>. Although accountability implies having to account for one’s actions, if the account given is considered insufficient, then one might still be considered blameworthy and thus deserving of censure or blame <span id="id3">[]</span>.</p>
<p>AI systems bring particular concerns with respect to accountability, as understanding how the systems work can be challenging, and commercial considerations can conceal broader organisations processes <span id="id4">[]</span>. Although one might “understand” the inner workings of the algorithms used, the outcomes might still not be predictable, complicating accountability even further <span id="id5">[]</span>.</p>
<p>Two often discussed examples to explain the accountability setting are related to autonomous driving cars and medical decisions.</p>
<p>Indeed, imagine a self-driving car that hits a pedestrian. Who should account for or justify the system’s actions? The person within the car that might not have been able or willing to supervise the system? The manufacturer, that designed the systems and thus should be the only responsible of the behaviour of its products? The programmer that did not correctly implement all the necessary checks? The manufacture of the sensor that did not detect the pedestrian? The person who conducted the test that did not foresee that particular circumstance?</p>
<p>Or, again, in the case of a wrong diagnosis following an MRI. Do we expect an account from the doctor that did not see the error or the AI system (at all the same possible levels we saw in the previous example)?</p>
<p>Given the difficulties, a lot of effort put in the definition of accountability regards the <strong>Auditability</strong> principle: <span id="id6">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span></p>
<blockquote>
<div><p>Auditability entails the enablement of the assessment of algorithms, data and design processes. This does not necessarily imply that information about business models and intellectual property related to the AI system must always be openly available. Evaluation by internal and external auditors, and the availability of such evaluation reports, can contribute to the trustworthiness of the technology. In applications affecting fundamental rights, including safety-critical applications, AI systems should be able to be independently audited.</p>
</div></blockquote>
<p>Other aspects took into consideration in the High Level Expert Group report <span id="id7">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span> are:</p>
<ul class="simple">
<li><p><strong>Minimisation and reporting of negative impacts</strong>, i.e., assessing, documenting and minimising the potential negative impacts of AI systems, even thanks to the use of impact assessments both prior to and during the development, deployment and use of AI systems.</p></li>
<li><p><strong>Trade-offs</strong> to tackle tensions that may arise between requirements. If conflict arises, trade-offs should be explicitly acknowledged and evaluated in terms of their risk to ethical principles, including fundamental rights.  Any decision about which trade-off to make should be reasoned and properly documented. Whether no ethically acceptable trade-offs can be identified, <span id="id8">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span> clearly states that the development, deployment and use of the AI system should not proceed in that form.</p></li>
<li><p><strong>Redress</strong> must be ensured when things go wrong, with particular attention to vulnerable persons or groups. The importance of the redress is advocated also by the European Union Agency for Fundamental Rights <span id="id9">[]</span>, where particular emphasis is posed to collective redress (i.e., collective redress, a way in which victims can join forces to overcome obstacles), and by the Council of Europe <span id="id10">[]</span>, where is specified that a citizen should not necessarily have to pursue legal action straight away and seeking remedies should be available, known, accessible, affordable and capable of providing appropriate redress.</p></li>
</ul>
</div>
<div class="section" id="guidelines">
<h2>Guidelines<a class="headerlink" href="#guidelines" title="Permalink to this headline">¶</a></h2>
<p>Several guidelines and checklists have been proposed to increase accountability over the actions of AI systems, both from EU authorities and industries, such as:</p>
<ul class="simple">
<li><p><strong>The Assessment List for Trustworthy Artificial Intelligence (ALTAI)</strong> <span id="id11">[]</span> <br>
This Assessment List (ALTAI) is firmly grounded in the protection of people’s fundamental rights exposed by the High Level Expert Group report <span id="id12">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span>. It is probably the most complete one so far and the reference point for all other checklists. <br>
The ALTAI checklist helps organisations understand what Trustworthy AI is, in particular what risks an AI system might generate, and how to minimize those risks while maximising the benefit of AI. It is intended to help organisations identify how proposed AI systems might generate risks, and to identify whether and what kind of active measures may need to be taken to avoid and minimise those risks. It aims at raising awareness of the potential impact of AI on society, the environment, consumers, workers and citizens (in particular children and people belonging to marginalised groups) and at encouraging the multidisciplinarity and the involvement of all relevant stakeholders. It helps to gain insight on whether meaningful and appropriate solutions or processes to accomplish adherence to the seven requirements (as outlined above) are already in place or need to be put in place. This could be achieved through internal guidelines, governance processes, etc. <br>
For each requirement, this Assessment List for Trustworthy AI (ALTAI) provides introductory guidance and relevant definitions in the Glossary. The <a href="https://futurium.ec.europa.eu/en/european-ai-alliance/pages/altai-assessment-list-trustworthy-artificial-intelligence" target=_blank>online version</a> of this assessment list contains additional explanatory notes for many of the questions.</p></li>
<li><p><strong>Getting the Future Right</strong> <span id="id13">[]</span><br>
The European Union Agency for Fundamental Rights published a report where a fundamental rights-based analysis of concrete ‘use cases’ is provided. The report illustrates some of the ways that companies and the public sector in the EU are looking to use AI to support their work, and whether – and how – they are taking fundamental rights considerations into account. In this way, it contributes empirical evidence, analysed from a fundamental rights perspective, that can inform EU and national policymaking efforts to regulate the use of AI tools.</p></li>
<li><p><strong>ICO’s guidance on the use of artificial intelligence</strong> <span id="id14">[]</span> <br>
The UK data protection authority has been very active on all the topics related to accountability, publishing guidance that is constantly updated. In <span id="id15">[]</span>, the focus of accountability is on being compliant with data protection law and being capable of minimise risks. It explores some important aspects such as Leadership and oversight (e.g., the structure of the analyzed organization), <a class="reference internal" href="../Transparency/Transparency.html"><span class="doc std std-doc">Transparency</span></a>, <a class="reference internal" href="../Privacy_and_Data_Governance/Privacy_and_Data_Governance.html"><span class="doc std std-doc">Privacy</span></a>, and <a class="reference internal" href="../Technical_Robustness_and_Safety/Technical_Robustness_and_Safety.html"><span class="doc std std-doc">Security</span></a>; a whole section is dedicated to the Data Protection Impact Assessment.<br>
In <span id="id16">[]</span>, a short checklist is presented, even if in the document itself is highlighted that “Accountability is not a box-ticking exercise”  but rather taking responsibility for what you are doing with personal data, considering this as an opportunity to develop and sustain people’s trust.</p></li>
<li><p><strong>IBM’s FactSheets</strong> <span id="id17">[]</span><br>
This document starts from Supplier’s Declarations of Conformity (SDoCs), which are documents largely used by many industries even if they are usually not legally required documents, to describe the lineage of a product along with the safety and performance testing it has undergone. SDoCs aims at capturing and quantifying various aspects of the product and its development to make it worthy of consumers’ trust. The chechlist proposed in <span id="id18">[]</span> should help increasing trust in AI services. We envision such documents to contain purpose, performance, safety, security, and provenance information to be completed by AI service providers for examination by consumers.<br>
A FactSheet will contain sections on all relevant attributes of an AI service, such as intended use, performance (including appropriate accuracy or risk measures along with timing information), safety, explainability, algorithmic fairness, and security and robustness. Moreover, the FactSheet should help in listing how the service was created, trained, and deployed along with what scenarios it was tested on, how it may respond to untested scenarios, guidelines that specify what tasks it should and should not be used for, and any ethical concerns of its use. Hence, FactSheets help prevent overgeneralization and unintended use of AI services by solidly grounding them with metrics and usage scenarios.
FactSheet is a quite interesting example because in this case a private company highlights the need of ethical procedures, standards, and certifications.</p></li>
<li><p><strong>Microsoft’s guideline for human-AI interaction</strong> <span id="id19">[]</span> <br>
In this paper, authors identified 18 question, related to different phases of the use of an AI system, and 10 different kinds of application, ranging from e-commerce recommender systems to route planning  systems, from automatic photo organizers to social network feed filtering systems. Then, authors empirically evaluated both the clarity and the relevance of various questions in the various domains, highlighting potential criticality (e.g., reporting a violation to the question ``Make clear why the system did what it did’’ if a recommender system did not non give any explanations of the reason why a certain product was suggested).</p></li>
</ul>
</div>
<div class="section" id="possible-taxonomy-of-terms">
<h2>Possible Taxonomy of terms<a class="headerlink" href="#possible-taxonomy-of-terms" title="Permalink to this headline">¶</a></h2>
<p>Boven <span id="id20">[]</span> defines accountability as</p>
<blockquote>
<div><p>a <strong>relationship</strong> between an <strong>actor</strong> and a <strong>forum</strong>, in which the actor has an obligation to <strong>explain and to justify</strong> his or her conduct, the forum can pose questions and pass judgement, and the actor may face <strong>consequences</strong>.</p>
</div></blockquote>
<p>Wiering <span id="id21">[]</span> presented a thorough systematic literature review on algorithmic accountability structured on the five points identified by Boven in his definition, which we briefly summarize below:</p>
<ul class="simple">
<li><p><strong>Arguments on the actor</strong>: Involves a broader discussion on who is responsible for the harm that the system may inflict
when it is working correctly, and who is responsible when it is
working incorrectly. It involves different levels of actors (e.g. individuals, teams, department, organizations) with different roles and possibly also third-parties. Due to these multiple levels and actors, situations known as ``the problem of many hands’’ might occur, in which the
collective can reasonably be held responsible for an outcome, while none
of the individuals can be reasonably held responsible for that outcome <span id="id22">[]</span>. In these situations, to be “in the loop” is not enough, calling for a more meaningful ability to control the design and operation process, in other words calling for meaningful human control. <!-- TODO: add link {doc}`L3.meaningful_human_control` --></p></li>
<li><p><strong>The forum</strong>: To whom a given account is directed. The forum might take different shapes such as political, legal, administrative, professional, and towards the civil society. Examples of forum include General Data Protection Regulation (GDPR), the proposed EU AI Act, or even the guidelines for trustworthy AI proposed by the European Commission <span id="id23">[<a class="reference internal" href="../Transparency/Transparency.html#id21">1</a>]</span>, as discussed in the previous section.</p></li>
<li><p><strong>The relationship between the actor and the forum</strong>: This relationship comes in different forms and shapes, according to all other four points. Nevertheless, they are usually mapped in three phases: the information phase, the deliberation and discussion phase, and the final phase, where consequences can be imposed on the actor by the forum.</p></li>
<li><p><strong>The content and criteria of the account</strong>: Although ex ante analysis, such as impact assessment and simulations, can be helpful, they are limited as they cannot foresee all possible behavior and consequences. The importance of an accountability relationship should depend not only on such ex ante factors, but also on the extent to which a given system impacts society and individuals.</p></li>
<li><p><strong>The consequences which may result from the account</strong>: In situations where there is a more “vertical” accountability relationship between actor and forum (e.g., accountability through legal standers), consequences are usually made more tangible. In more “horizontal” settings (e.g., self-regulation of organizations), consequences are defined based more on a moral imperative.</p></li>
</ul>
</div>
<div class="section" id="accountability-gaps-and-their-implications">
<h2>Accountability gaps and their implications<a class="headerlink" href="#accountability-gaps-and-their-implications" title="Permalink to this headline">¶</a></h2>
<p>As AI systems, especially systems with learning abilities, are deployed “in the wild”, human control and prediction over their behaviour are very difficult if not impossible, leading to so-called <em>“accountability gaps”</em>. Santoni de Sio &amp; Mecacci <span id="id24">[]</span> divided such gaps in public accountability gap and moral accountability gaps. <em>Public accountability gaps</em> relate to citizens not being able to get an explanation for decisions taken by public agencies, while <em>moral accountability gap</em> refers to the reduction of human agents’ capacity to make sense of – and explain to each other the behaviour of AI systems.</p>
<p>Accountability gaps point to the fact that accounting requires knowledge and some ability to control <span id="id25">[]</span>. Designers and developers of AI systems can only tackle this challenge by acknowledging that this is not a matter of fortuitous allocation of praise or blame, and that systems should be developed in a manner that allows for stakeholders to be held accountable. Among other things, this relates to the social context where these systems are deployed (and whether a given solution or formulation can be argued), how the questions and criteria for accountability are framed, and the level of understanding and control that a given actor might have. In this encyclopedia, we discuss these three interrelated concepts, respectively, in the entries <a class="reference internal" href="L3.Wicked_problems.html"><span class="doc">Wicked problems</span></a>, <a class="reference internal" href="L3.The_frame_problem.html"><span class="doc">The Frame Problem</span></a>, and <a class="reference internal" href="../Human_Agency_and_Oversight/Meaningful_human_control.html"><span class="doc">Meaningful human control</span></a>.</p>
</div>
<div class="section" id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<span class="target" id="id26"></span><blockquote>
<div><p>This entry was written by Luciano C Siebert and Francesca Pratesi.</p>
</div></blockquote>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Accountability"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Accountability_and_Reproducibility.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Accountability and Reproducibility</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="L3.Wicked_problems.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Wicked problems</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          Di TAILOR WP3 members; see <a href="/handbookTAI/authors.html" target="_blank">here</a> for the complete list of contributors. This research was partially supported by TAILOR, a project funded by EU Horizon 2020 research and innovation programme under GA No 952215<br/>
        
            &copy; Diritto d'autore 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>