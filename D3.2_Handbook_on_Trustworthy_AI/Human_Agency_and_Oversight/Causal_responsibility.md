# Causal Responsibility

## In brief

Causal responsibility is the notion of responsibility that is concerned with actual causation {cite}`vincentStructuredTaxonomyResponsibility2011,chocklerResponsibilityBlameStructuralModel2004, englTheoryCausalResponsibility2018`.

## More in detail

**Causal responsibility** is a notion of responsibility that captures the causal influence an event, or an agent's action or omission has on a particular outcome or state of affairs {cite}`vincentStructuredTaxonomyResponsibility2011,chocklerResponsibilityBlameStructuralModel2004,englTheoryCausalResponsibility2018`. In the context of human-AI systems, *human causal responsibility* captures the actual causal influence the human has on an outcome while interacting with the AI system.

Apart from causal responsibility, {cite}`vincentStructuredTaxonomyResponsibility2011` identifies five other notions of responsibility: capacity responsibility, role responsibility, outcome responsibility, virtue responsibility and legal liability. She goes on to explain how causal responsibility is a prerequisite for outcome responsibility which is in turn a prerequisite for legal liability. To ascribe praise, blame or moral responsibility to the actions of an agent, causal responsibility is a necessary condition {cite}`brahamAnatomyMoralResponsibility2012, vandepoelEthicsTechnologyEngineering2011`. When ascribing praise or blame to an an agent's actions, in addition to causal influence, considerations about the intentions, epistemic conditions and roles of the agent are taken into account. Nonetheless, causal responsibility plays a crucial role in debates about responsibility and legal liability {cite}`hartPunishmentResponsibility2008,hartCausationLaw1985`. 

Counterfactual reasoning which is predominantly associated with determining actual causality has also been popular in approaches for evaluating causal responsibility {cite}`chocklerResponsibilityBlameStructuralModel2004,englTheoryCausalResponsibility2018,duijfLogicalStudyMoral2023,triantafyllouActualCausalityResponsibility2022,loriniLogicalAnalysisResponsibility2014`. In counterfactual reasoning, we check whether an agent's action is pivotal for the outcome, i.e., whether changing the agent's action would prevent an outcome from happening. In {cite}`chocklerResponsibilityBlameStructuralModel2004` was defined a graded metric for causal responsibility based on the number of changes that have to be made to make an agent's action pivotal for an outcome, while in {cite}`george2023measuring` was proposed a notion of causal responsibility in spatial settings based on how one agent restricts the feasible action space of another agent in a concurrent game setting. Related models of group responsibility have also been suggested which are primarily focused on the ability of groups of agents to cause or prevent an outcome or state of affairs {cite}`yazdanpanahDistantGroupResponsibility2016,yazdanpanahApplyingStrategicReasoning2021`. Concerning human-AI interaction, Douer and Meyer have opted an information theoretic approach to propose a metric for human causal responsibility based on how human actions affect the distribution of the outcomes of the human-AI system {cite}`douerResponsibilityQuantificationModel2020`. 

Disentangling causal responsibility is tricky when it comes to complex human-AI systems {cite}`dignumResponsibleArtificialIntelligence2019`. Nonetheless, understanding the causal influences of different agents is crucial for identifying who should change their behaviour for better satisfying relevant human values and ethical principles. For systems to be under meaningful human control, we should be able to the trace the responsibility to the right human(s) and to ensure that the right humans have control over the outcomes {cite}`santonidesioMeaningfulHumanControl2018,flemischDynamicBalanceHumans2012`. Also teaching AI systems to reason about responsibility is crucial for making AI systems trustworthy {cite}`dastaniResponsibilityAISystems2023`.

## Bibliography

```{bibliography} ../references.bib
:style: unsrt
:filter: docname in docnames
```

> This entry was written by George Ashwin.
