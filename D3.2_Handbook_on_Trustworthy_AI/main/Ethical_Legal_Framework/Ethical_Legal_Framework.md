# The Ethical and Legal Framework

<!-- TODO 

point the link
[risk-based approach](./Ethical_Legal_Framework/AI_ACT.md}
to the correct section of the entry


-->

In these pages, we focus on the European framework only, mostly relying on two main sources, which are described below and in the linked pages.

The first document, at least chronologically speaking, we refer to is the [Ethical Guidelines for Trustworthy AI](./Ethical_Legal_Framwework/HLEG) {cite}`HLEG`, which, as the name itself suggests is not a law or a legal obligation. Nevertheless, it is commonly recognized as the most relevant document in the field of Trustworthy AI.
Here, as we already mentioned, there are listed a definition of Trustworthy AI, the foundation of Trustworthy AI, the seven key requirements that AI systems should implement and meet throughout their entire life cycle, and a concrete assessment list to operationalize the requirements.

Then, the other fundamental source is the world's first comprehensive law on Artificial Intelligence (AI): the [EU AI Act](./Ethical_Legal_Framwework/AI_ACT) {cite}`AIACT`. The text provides a classification of AI systems using a [risk-based approach](./Ethical_Legal_Framework/AI_ACT.md}; four levels of risk were identified, and different obligations are listed for the different categories of AI systems to be compliant with this law.

```{bibliography} ../../references.bib
:style: unsrt
:filter: docname in docnames
```

> This entry was written by Francesca Pratesi and Umberto Straccia.
