# The Problem of Many Hands

## In brief

Who is morally responsible in a situation with several actors?

## More in detail

When a bridge fails or an algorithm makes a mistake, who is held responsible? Sure in some situations, there may be a clear culprit, but in many situations like these we've had several agents involved. In policy making there are often many public officials who carry a part of the responsibility, which can make it difficult even in principle to identify who is morally responsibly {cite}`thompson1980moral`. In complex engineering projects, accidents may occur because of highly complex coincidences that are hard to foresee {cite}`van2012problem`. This phenomenon which arises due to complexity and amount of actors, makes it almost impossible to hold someone reasonably responsible is often referred to as the problem of many hands. This has much to do with the fact that there is no locus of decision-making, no single individuals is blameworthy for the harm caused {cite}`nissenbaum1996accountability`. This is not to say that there is no more responsibility at all, rather that it is diffuse and that it is hard to identify the appropriate person who ought to make amends for the outcome {cite}`nissenbaum1994computing`.

This problem becomes more pressing once we add technology into the mix. The physical and temporal distance introduced by technology means that the connection between actions and events is further blurred {cite}`friedman1990moral`. Technology can propagate one's action through time and space, being social media a familiar example of this, as it allows us to be vocal towards a far larger crowd than ever before. Before going on about moral responsibility, one should note that the introduction of many different systems, and interaction between systems, could also cause similar problems. The internet-of-things era that we are living in, may for example also cause accidents (conflicts between different systems). The complexity that arises from the interaction between systems may also make it hard to know which particular systems are to blame.

Nonetheless, if we are looking for moral individual responsibility, we need to know what kind of responsibility that is? Roughly speaking one can divide this between backward-looking and forward-looking {cite}`van2011relation`. Backward-looking responsibility is a kind of accountability and blameworthiness, as in: this individual can reasonably be blamed for a particular outcome. Forward-looking means an agent can be reasonably expected to prevent a particular state of affairs, it can be seen as an obligation to prevent the harm from happening in the first place. The reason this difference may be of importance is because the difference in responsibility attribution may differ for these two types of responsibilities. Technology for example is built, but also applied and wielded, and during that application it may be used in a context for which it was not appropriate. This may thus complicate the notion of a kind of forward-looking responsibility because it is hard to know under which conditions something is used in the future. Yet, under which condition is it acceptable to hide behind such a statement? In a sense this relates back to backward-looking as a designer may have had influence to prevent that that application in said context in the first place. In a sense, accountability can be approached both through backward-looking and forward-looking, but they imply something different about what our relation to responsibility and accountability ought to be in such considerations.

## Bibliography

```{bibliography} ../references.bib
:style: unsrt
:filter: docname in docnames
```

> This entry was written by Sietze Kuilman.









